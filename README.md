# Computational Intelligence for Games Final Project

For my final project for this course, I wrote a Monte-Carlo Tree Search solution to the game of checkers, a two-player, turn-based, non-stochastic game where both players have perfect information. In checkers, each player has 12 pieces and can move their pieces diagonally forward on a checkerboard. Players can jump their opponent's pieces to take them off the board. If a player's piece reaches the other side, it becomes a king and can now move diagonally backwards too. The goal is to remove all of your opponent's pieces from the board.

To solve this, first I modified ImparaAI's checkers implementation (https://github.com/ImparaAI/checkers). This included finding a way to make the game test playouts without permanently changing the state of the board. Then, I wrote a heuristic function, which weighted different values like: how many pieces on the board, what pieces are on the board, mobility value (number of legal moves per each player), and distance from being a king. The heuristic strategy is to select the next possible move with the highest heuristic value. Finally, I modified our MCTS project from class, using a new reward system, the checkers implementation (which included having to create a state because using an object as a hash table key is finnicky), and an epsilon greedy default policy in which 80% of the time the heuristic strategy is chosen from the possible moves and 20% of the time a random move is chosen. Important note: I have discovered that in this implementation of get_possible_moves(), if even one capture move is available, it will only return capture moves. So, the random strategy is a little better than random!

My results: In a competition between a heuristic strategy and random strategy, out of 1000 games, the heuristic strategy wins: 99.5% of the time. As for the rest, my program has been running for over 2 hours and unfortunately still has not tested a significant amount of games and iterations (20 games, 200 depth mcts), so I will have to make an educated guess on its success. In a competition between an MCTS algorithm (with 100 depth) and random strategy, out of 5 games, the MCTS algorithm wins: ~75% of the time. Finally, in a competition between an MCTS algorithm (with 100 depth) and heuristic strategy, out of 5 games, the MCTS algorithm wins: ~50% of the time.
